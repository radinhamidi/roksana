{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Adversarial Attack Evaluation\n",
    "-----------------------------------\n",
    "This script evaluates the performance of a Graph search before and after applying adversarial attacks using the Attack method on a dataset.\n",
    "\n",
    "Steps:\n",
    "1. Load the Cora dataset.\n",
    "2. Prepare a search set with queries.\n",
    "3. Initialize the GCN search method and attack method.\n",
    "4. Perform adversarial attacks on selected nodes.\n",
    "5. Evaluate the performance of GCN before and after the attack.\n",
    "6. Save evaluation results to CSV, JSON, and Pickle formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from roksana.search_methods import get_search_method\n",
    "from roksana.datasets import load_dataset, prepare_search_set\n",
    "from roksana.evaluation import Evaluator, save_results_to_pickle, save_results_to_json\n",
    "from roksana.attack_methods import get_attack_method\n",
    "from roksana.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function to execute the adversarial attack evaluation workflow.\n",
    "\n",
    "Steps:\n",
    "- Load the dataset.\n",
    "- Prepare a search set for evaluation.\n",
    "- Initialize the GCN search method and VikingAttack.\n",
    "- Perform attacks on query nodes and apply the changes to the dataset.\n",
    "- Evaluate GCN performance before and after the attack.\n",
    "- Save evaluation results in multiple formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA_LAUNCH_BLOCKING for debugging\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cora dataset\n",
    "dataset = load_dataset(dataset_name='cora', root='data/')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test set with 10% of nodes as queries\n",
    "queries, query_features, gold_sets = prepare_search_set(data, percentage=0.1, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Epoch: 001, Loss: 4.1796, Train Acc: 0.6143\n",
      "GCN Epoch: 010, Loss: 0.5383, Train Acc: 0.9786\n",
      "GCN Epoch: 020, Loss: 0.0429, Train Acc: 1.0000\n",
      "GCN Epoch: 030, Loss: 0.0064, Train Acc: 1.0000\n",
      "GCN Epoch: 040, Loss: 0.0021, Train Acc: 1.0000\n",
      "GCN Epoch: 050, Loss: 0.0011, Train Acc: 1.0000\n",
      "GCN Epoch: 060, Loss: 0.0008, Train Acc: 1.0000\n",
      "GCN Epoch: 070, Loss: 0.0007, Train Acc: 1.0000\n",
      "GCN Epoch: 080, Loss: 0.0006, Train Acc: 1.0000\n",
      "GCN Epoch: 090, Loss: 0.0005, Train Acc: 1.0000\n",
      "GCN Epoch: 100, Loss: 0.0005, Train Acc: 1.0000\n",
      "GCN Epoch: 110, Loss: 0.0005, Train Acc: 1.0000\n",
      "GCN Epoch: 120, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 130, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 140, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 150, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 160, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 170, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 180, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 190, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 200, Loss: 0.0003, Train Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GCN search method before attack\n",
    "gcn_before = get_search_method('gcn', data=data, hidden_channels=64, epochs=200, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the attack method\n",
    "attack_method = get_attack_method('random', data=data, perturbations=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Removed Edges in the list: 270\n",
      "Number of Duplicate Edges: 2\n",
      "Number of Unique Edges to Remove: 268\n",
      "Number of Removed Edges with Reversed Counterparts in Graph: 268\n",
      "Number of Total Removed Edges: 536\n"
     ]
    }
   ],
   "source": [
    "# Perform attacks on all query nodes\n",
    "removed_edges_list = []\n",
    "for query in queries:\n",
    "    tensor_query = torch.tensor(query, device=device)\n",
    "    updated_data, removed_edge = attack_method.attack(data=data, selected_nodes=tensor_query)\n",
    "    removed_edges_list.append(removed_edge)\n",
    "removed_edges_list_stat(data, removed_edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all removed edges to the final data \n",
    "# for edge in removed_edges_list:\n",
    "attacked_data = remove_edges(data, removed_edges_list, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________\n",
      "- Compare\n",
      "____________________________________________\n",
      "Number of nodes (Original): 2708\n",
      "Number of nodes (Updated): 2708\n",
      "Number of edges (Original): 10556\n",
      "Number of edges (Updated): 10020\n",
      "\n",
      "Difference in the number of edges: 536\n",
      "____________________________________________\n",
      "____________________________________________\n"
     ]
    }
   ],
   "source": [
    "compare_original_vs_updated(data, attacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Epoch: 001, Loss: 4.1785, Train Acc: 0.6214\n",
      "GCN Epoch: 010, Loss: 0.6218, Train Acc: 0.9643\n",
      "GCN Epoch: 020, Loss: 0.0627, Train Acc: 1.0000\n",
      "GCN Epoch: 030, Loss: 0.0090, Train Acc: 1.0000\n",
      "GCN Epoch: 040, Loss: 0.0028, Train Acc: 1.0000\n",
      "GCN Epoch: 050, Loss: 0.0015, Train Acc: 1.0000\n",
      "GCN Epoch: 060, Loss: 0.0010, Train Acc: 1.0000\n",
      "GCN Epoch: 070, Loss: 0.0008, Train Acc: 1.0000\n",
      "GCN Epoch: 080, Loss: 0.0007, Train Acc: 1.0000\n",
      "GCN Epoch: 090, Loss: 0.0006, Train Acc: 1.0000\n",
      "GCN Epoch: 100, Loss: 0.0006, Train Acc: 1.0000\n",
      "GCN Epoch: 110, Loss: 0.0005, Train Acc: 1.0000\n",
      "GCN Epoch: 120, Loss: 0.0005, Train Acc: 1.0000\n",
      "GCN Epoch: 130, Loss: 0.0005, Train Acc: 1.0000\n",
      "GCN Epoch: 140, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 150, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 160, Loss: 0.0004, Train Acc: 1.0000\n",
      "GCN Epoch: 170, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 180, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 190, Loss: 0.0003, Train Acc: 1.0000\n",
      "GCN Epoch: 200, Loss: 0.0003, Train Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GCN search method after attack\n",
    "gcn_after = get_search_method('gcn', data=attacked_data, hidden_channels=64, epochs=200, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Evaluator\n",
    "evaluator = Evaluator(\n",
    "    search_method_before=gcn_before,\n",
    "    search_method_after=gcn_after,\n",
    "    k_values=[5, 10, 20]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to evaluation_results/gcn_attack_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation and save results to CSV\n",
    "evaluator.evaluate(\n",
    "    queries=torch.tensor(queries).to(device),\n",
    "    gold_sets=gold_sets,\n",
    "    results_dir='evaluation_results',\n",
    "    filename='gcn_attack_evaluation.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results successfully saved to evaluation_results/gcn_attack_evaluation.json in JSON format.\n",
      "Results successfully saved to evaluation_results/gcn_attack_evaluation.pkl in Pickle format.\n"
     ]
    }
   ],
   "source": [
    "# Optionally, save results to JSON or Pickle\n",
    "results = evaluator.get_all_results()  # Assuming you have a method to retrieve all results\n",
    "save_results_to_json(results, 'evaluation_results/gcn_attack_evaluation.json')\n",
    "save_results_to_pickle(results, 'evaluation_results/gcn_attack_evaluation.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roksana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
